import streamlit as st
import pandas as pd
import requests
import base64
import json
import io
from pdf2image import convert_from_bytes
import time

# --- âš ï¸ å¡«å…¥ä½ çš„ SiliconFlow Key ---
API_KEY = "sk-epvburmeracnfubnwswnzspuylzuajtoncrdsejqefjlrmtw" 

# --- å¤‡é€‰æ¨¡å‹åå• ---
CANDIDATE_MODELS = [
    "Qwen/Qwen2-VL-72B-Instruct",       # ä¼˜å…ˆå°è¯•å¤§æ¨¡å‹
    "Qwen/Qwen2-VL-7B-Instruct",        # å¤‡é€‰å°æ¨¡å‹
    "deepseek-ai/deepseek-vl-7b-chat",
    "TeleAI/TeleMM"
]

API_URL = "https://api.siliconflow.cn/v1/chat/completions"

def analyze_image_auto_switch(image_bytes, mime_type):
    """è‡ªåŠ¨è½®è¯¢æ¨¡å‹ï¼Œç›´åˆ°æˆåŠŸ"""
    base64_image = base64.b64encode(image_bytes).decode('utf-8')
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    
    last_error = ""

    for model_name in CANDIDATE_MODELS:
        status_placeholder = st.empty()
        status_placeholder.caption(f"ğŸ”„ æ­£åœ¨å°è¯•: {model_name} ...")
        
        data = {
            "model": model_name,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "Extract invoice data into JSON: 1.Item 2.Date 3.Total. JSON format: {\"Item\":\"x\",\"Date\":\"x\",\"Total\":0}"},
                        {"type": "image_url", "image_url": {"url": f"data:{mime_type};base64,{base64_image}"}}
                    ]
                }
            ],
            "max_tokens": 512,
            "temperature": 0.1
        }

        try:
            response = requests.post(API_URL, headers=headers, json=data, timeout=45)
            
            if response.status_code == 200:
                status_placeholder.empty()
                content = response.json()['choices'][0]['message']['content']
                clean = content.replace("```json", "").replace("```", "").strip()
                s = clean.find('{')
                e = clean.rfind('}') + 1
                return json.loads(clean[s:e]) if s != -1 else json.loads(clean)
            
            elif response.status_code == 403:
                status_placeholder.empty()
                if "7B" in model_name:
                    raise Exception("ä½™é¢ä¸è¶³ï¼Œè¯·æ£€æŸ¥ SiliconFlow è´¦å·ã€‚")
                continue
            else:
                status_placeholder.empty()
                continue

        except Exception as e:
            status_placeholder.empty()
            last_error = str(e)
            continue
            
    raise Exception(f"æ‰€æœ‰æ¨¡å‹å‡ä¸å¯ç”¨ã€‚æœ€åæŠ¥é”™: {last_error}")

# --- é¡µé¢é€»è¾‘ ---
st.set_page_config(page_title="å‘ç¥¨åŠ©æ‰‹ (å¯ç¼–è¾‘ç‰ˆ)", layout="wide")
st.title("ğŸ§¾ å‘ç¥¨åŠ©æ‰‹ (QwenVL å¯ç¼–è¾‘ç‰ˆ)")

# 1. åˆå§‹åŒ–è®°å¿†ç¼“å­˜
if 'invoice_cache' not in st.session_state:
    st.session_state.invoice_cache = {}

# ğŸŸ¢ æ–°å¢ï¼šåˆå§‹åŒ–â€œå·²åˆ é™¤æ–‡ä»¶â€åˆ—è¡¨
if 'ignored_files' not in st.session_state:
    st.session_state.ignored_files = set()

uploaded_files = st.file_uploader("è¯·ä¸Šä¼ å‘ç¥¨", type=['png', 'jpg', 'jpeg', 'pdf'], accept_multiple_files=True)

if uploaded_files:
    st.divider()
    
    # ç­›é€‰å‡ºéœ€è¦å¤„ç†çš„æ–°æ–‡ä»¶ï¼ˆæ’é™¤å·²ç¼“å­˜çš„ å’Œ å·²è¢«ç”¨æˆ·åˆ é™¤çš„ï¼‰
    new_files = []
    for file in uploaded_files:
        file_id = f"{file.name}_{file.size}"
        # åªæœ‰å½“å®ƒæ—¢æ²¡åœ¨ç¼“å­˜é‡Œï¼Œä¹Ÿæ²¡åœ¨åˆ é™¤åˆ—è¡¨é‡Œï¼Œæ‰ç®—æ–°æ–‡ä»¶
        if file_id not in st.session_state.invoice_cache and file_id not in st.session_state.ignored_files:
            new_files.append(file)
    
    if new_files:
        progress_bar = st.progress(0)
        st.info(f"æ£€æµ‹åˆ° {len(new_files)} å¼ æ–°å‘ç¥¨ï¼Œå‡†å¤‡å¼€å§‹è¯†åˆ«...")
    
    current_data_list = []
    
    # === ä¸»å¾ªç¯ï¼šå‡†å¤‡æ˜¾ç¤ºçš„æ•°æ® ===
    for index, file in enumerate(uploaded_files):
        file_id = f"{file.name}_{file.size}"
        
        # ğŸŸ¢ å¦‚æœè¿™ä¸ªæ–‡ä»¶ä¹‹å‰è¢«ç”¨æˆ·åˆ é™¤äº†ï¼Œå°±è·³è¿‡ä¸æ˜¾ç¤º
        if file_id in st.session_state.ignored_files:
            continue

        # æ£€æŸ¥ç¼“å­˜
        if file_id in st.session_state.invoice_cache:
            result = st.session_state.invoice_cache[file_id]
        else:
            try:
                # è¯†åˆ«é€»è¾‘
                file_bytes = file.read()
                process_bytes = file_bytes
                mime_type = file.type
                
                if file.type == "application/pdf":
                    images = convert_from_bytes(file_bytes)
                    if images:
                        img_buffer = io.BytesIO()
                        images[0].save(img_buffer, format="JPEG")
                        process_bytes = img_buffer.getvalue()
                        mime_type = "image/jpeg"
                if mime_type == 'image/jpg': mime_type = 'image/jpeg'

                result = analyze_image_auto_switch(process_bytes, mime_type)
                
                if result:
                    st.session_state.invoice_cache[file_id] = result
                    st.toast(f"âœ… {file.name} è¯†åˆ«æˆåŠŸ")
                
                if file in new_files:
                    curr_progress = (new_files.index(file) + 1) / len(new_files)
                    progress_bar.progress(curr_progress)

            except Exception as e:
                st.error(f"âŒ {file.name} å¤±è´¥: {e}")
                result = None

        # æ•´ç†æ•°æ®
        if result:
            try:
                raw_amt = str(result.get('Total', 0)).replace('Â¥','').replace(',','').replace('å…ƒ','')
                amt = float(raw_amt)
            except:
                amt = 0.0
            
            current_data_list.append({
                "æ–‡ä»¶å": file.name,
                "æ—¥æœŸ": result.get('Date', ''),
                "é¡¹ç›®": result.get('Item', ''),
                "é‡‘é¢": amt,
                "file_id": file_id # ğŸŸ¢ åŸ‹å…¥éšå½¢IDï¼Œç”¨äºè¿½è¸ªç¼–è¾‘å’Œåˆ é™¤
            })

    # === ç»“æœå±•ç¤ºä¸ç¼–è¾‘ ===
    if current_data_list:
        df = pd.DataFrame(current_data_list)
        
        # ğŸŸ¢ æ ¸å¿ƒä¿®æ”¹ï¼šä½¿ç”¨ data_editor ä»£æ›¿ dataframe
        st.caption("âœ¨ æç¤ºï¼šæ‚¨å¯ä»¥ç›´æ¥åœ¨ä¸‹æ–¹è¡¨æ ¼ä¸­ **ä¿®æ”¹å†…å®¹**ï¼Œæˆ–é€‰ä¸­è¡Œå¹¶æŒ‰ Delete é”®(æˆ–ç‚¹å‡»å³ä¾§åƒåœ¾æ¡¶) **åˆ é™¤è¡Œ**ã€‚")
        
        edited_df = st.data_editor(
            df,
            column_config={
                "file_id": None, # éšè— ID åˆ—ï¼Œç”¨æˆ·çœ‹ä¸åˆ°
                "é‡‘é¢": st.column_config.NumberColumn(format="%.2f"),
                "æ–‡ä»¶å": st.column_config.TextColumn(disabled=True) # æ–‡ä»¶åè®¾ä¸ºåªè¯»ï¼Œé˜²æ­¢æ”¹ä¹±
            },
            num_rows="dynamic", # ğŸŸ¢ å…è®¸å¢åˆ è¡Œ
            use_container_width=True,
            key="invoice_editor"
        )
        
        # === ğŸŸ¢ åŒæ­¥é€»è¾‘ï¼šå¤„ç†ç”¨æˆ·çš„ç¼–è¾‘å’Œåˆ é™¤ ===
        
        # 1. è¯†åˆ«è¢«åˆ é™¤çš„è¡Œ
        # å¯¹æ¯”åŸå§‹ ID å’Œ ç¼–è¾‘åçš„ IDï¼Œæ‰¾å‡ºå°‘äº†è°
        original_ids = set(df["file_id"])
        current_ids = set(edited_df["file_id"])
        deleted_ids = original_ids - current_ids
        
        if deleted_ids:
            # å°†åˆ é™¤çš„æ–‡ä»¶IDåŠ å…¥â€œé»‘åå•â€ï¼Œé˜²æ­¢ä¸‹æ¬¡åˆ·æ–°åˆè·³å‡ºæ¥
            st.session_state.ignored_files.update(deleted_ids)
            # ç«‹å³åˆ·æ–°é¡µé¢ï¼Œè®©åˆ é™¤æ•ˆæœæ›´å¹²è„†
            st.rerun()

        # 2. è¯†åˆ«è¢«ä¿®æ”¹çš„è¡Œï¼Œå¹¶åå‘æ›´æ–°ç¼“å­˜
        # è¿™æ ·ä½ ä¿®æ”¹äº†é‡‘é¢åï¼Œä¸‹è½½ Excel ä¹Ÿæ˜¯æ”¹å¥½çš„é‡‘é¢
        for index, row in edited_df.iterrows():
            fid = row['file_id']
            # å¦‚æœç¼“å­˜é‡Œæœ‰è¿™ä¸ªæ–‡ä»¶ï¼Œæ›´æ–°å®ƒçš„æ•°æ®
            if fid in st.session_state.invoice_cache:
                cached_item = st.session_state.invoice_cache[fid]
                # åªæœ‰å½“æ•°æ®çœŸçš„å˜äº†æ‰æ›´æ–°ï¼ˆè™½ç„¶ç›´æ¥èµ‹å€¼ä¹Ÿæ²¡é—®é¢˜ï¼‰
                cached_item['Date'] = row['æ—¥æœŸ']
                cached_item['Item'] = row['é¡¹ç›®']
                cached_item['Total'] = row['é‡‘é¢']

        # === ç»Ÿè®¡ä¸ä¸‹è½½ (ä½¿ç”¨ç¼–è¾‘åçš„ edited_df) ===
        
        total = edited_df['é‡‘é¢'].sum()
        st.metric("ğŸ’° æ€»é‡‘é¢", f"Â¥ {total:,.2f}")
        
        # å¯¼å‡º Excel (å»æ‰éšè—çš„ file_id åˆ—)
        df_export = edited_df.drop(columns=["file_id"])
        df_export.loc[len(df_export)] = ['åˆè®¡', '', '', total]
        
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df_export.to_excel(writer, index=False)
            
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ Excel è¡¨æ ¼ (åŒ…å«ä¿®æ”¹)", 
            data=output.getvalue(), 
            file_name="å‘ç¥¨æ±‡æ€».xlsx", 
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary"
        )
