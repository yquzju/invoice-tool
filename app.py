import streamlit as st
import pandas as pd
import requests
import base64
import json
import io
from pdf2image import convert_from_bytes
import time

# --- 1. é…ç½®åŒºåŸŸ ---
API_KEY = "sk-epvburmeracnfubnwswnzspuylzuajtoncrdsejqefjlrmtw"
API_URL = "https://api.siliconflow.cn/v1/chat/completions"
CANDIDATE_MODELS = ["Qwen/Qwen2-VL-72B-Instruct", "Qwen/Qwen2-VL-7B-Instruct", "TeleAI/TeleMM"]

# --- 2. æ³¨å…¥ CSS ---
st.markdown("""
    <style>
    div.stDownloadButton > button {
        background-color: #007bff !important; color: white !important; border: none !important;
        padding: 0.5rem 1.2rem !important; border-radius: 8px !important; width: auto !important;
    }
    div.stDownloadButton > button:hover { background-color: #0056b3 !important; }
    button[data-testid="baseButton-primary"] p::before { content: none !important; }
    .total-container { display: flex; align-items: baseline; justify-content: flex-end; gap: 15px; }
    .total-label { font-size: 1.2rem; color: #6C757D; }
    .total-value { font-size: 2rem; font-weight: 700; color: #212529; }
    </style>
""", unsafe_allow_html=True)

# --- 3. æ ¸å¿ƒè¯†åˆ«å‡½æ•° ---
def analyze_invoice(image_bytes, mime_type, log_placeholder):
    base64_image = base64.b64encode(image_bytes).decode('utf-8')
    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
    prompt = "Extract invoice data into JSON: 1.Item (Name), 2.Date (YYYY-MM-DD), 3.Total (Grand Total including tax/ä»·ç¨åˆè®¡). JSON format: {\"Item\":\"x\",\"Date\":\"x\",\"Total\":0}"

    for model in CANDIDATE_MODELS:
        if log_placeholder: log_placeholder.markdown(f"&nbsp;&nbsp;ğŸ”„ æ­£åœ¨è¿æ¥æ¨¡å‹ï¼š`{model}` ...")
        data = {
            "model": model,
            "messages": [{"role": "user", "content": [{"type": "text", "text": prompt}, {"type": "image_url", "image_url": {"url": f"data:{mime_type};base64,{base64_image}"}}]}],
            "max_tokens": 512, "temperature": 0.1
        }
        try:
            resp = requests.post(API_URL, headers=headers, json=data, timeout=30)
            if resp.status_code == 200:
                content = resp.json()['choices'][0]['message']['content']
                clean = content.replace("```json", "").replace("```", "").strip()
                s, e = clean.find('{'), clean.rfind('}') + 1
                return json.loads(clean[s:e])
            elif resp.status_code == 429: # é™æµ
                if log_placeholder: log_placeholder.warning(f"âš ï¸ è§¦å‘é™æµ (429)ï¼Œæ­£åœ¨å†·å´ 2ç§’...")
                time.sleep(2)
        except Exception: continue
    return None

# --- 4. é¡µé¢ä¸»ç¨‹åº ---
st.set_page_config(page_title="AI å‘ç¥¨åŠ©æ‰‹", layout="wide")
st.title("ğŸ§¾ AI å‘ç¥¨åŠ©æ‰‹ (å¯è§†åŒ–æ§åˆ¶å°ç‰ˆ)")

# åˆå§‹åŒ– Session State
if 'invoice_cache' not in st.session_state: st.session_state.invoice_cache = {}
if 'ignored_files' not in st.session_state: st.session_state.ignored_files = set()
# å…³é”®ï¼šè®°å½•æœ¬è½®ä¼šè¯å·²å°è¯•è¿‡çš„æ–‡ä»¶ï¼Œé˜²æ­¢æ­»å¾ªç¯è‡ªåŠ¨é‡è¯•
if 'processed_session_ids' not in st.session_state: st.session_state.processed_session_ids = set()

uploaded_files = st.file_uploader("è¯·ä¸Šä¼ å‘ç¥¨", type=['png', 'jpg', 'jpeg', 'pdf'], accept_multiple_files=True)

if uploaded_files:
    st.divider()
    
    # 1. æ™ºèƒ½ç­›é€‰ï¼šåªå¤„ç† (æœªç¼“å­˜ OR ç¼“å­˜å¤±è´¥) AND (æœ¬è½®æœªå°è¯•è¿‡) çš„æ–‡ä»¶
    queue_to_process = []
    for f in uploaded_files:
        fid = f"{f.name}_{f.size}"
        if fid in st.session_state.ignored_files: continue
        
        # æ ¸å¿ƒé€»è¾‘ï¼šå¦‚æœæ–‡ä»¶ä¸åœ¨ç¼“å­˜é‡Œï¼Œæˆ–è€…ä¹‹å‰å¤±è´¥äº†ï¼Œä¸”æœ¬è½®è¿˜æ²¡è¯•è¿‡ï¼ŒåŠ å…¥é˜Ÿåˆ—
        is_cached = fid in st.session_state.invoice_cache
        is_failed_before = is_cached and st.session_state.invoice_cache[fid].get('status') == 'failed'
        has_tried_this_session = fid in st.session_state.processed_session_ids
        
        if (not is_cached or is_failed_before) and not has_tried_this_session:
            queue_to_process.append(f)

    # 2. æ‰¹é‡å¤„ç†é˜Ÿåˆ—
    if queue_to_process:
        with st.status("ğŸš€ æ­£åœ¨æ‰§è¡Œæ‰¹é‡è¯†åˆ«ä»»åŠ¡...", expanded=True) as status_box:
            total_tasks = len(queue_to_process)
            success_count = 0
            fail_count = 0
            
            # è¿›åº¦æ¡ä¸çŠ¶æ€æ˜¾ç¤º
            progress_bar = st.progress(0)
            stats_text = st.empty()
            current_log = st.empty()
            
            for i, file in enumerate(queue_to_process):
                fid = f"{file.name}_{file.size}"
                # æ ‡è®°è¯¥æ–‡ä»¶æœ¬è½®å·²å°è¯•ï¼Œæ— è®ºæˆè´¥ï¼Œé˜²æ­¢æ­»å¾ªç¯
                st.session_state.processed_session_ids.add(fid)
                
                # æ›´æ–°é¢æ¿ä¿¡æ¯
                stats_text.markdown(f"ğŸ“Š **è¿›åº¦**: æˆåŠŸ `{success_count}` | å¤±è´¥ `{fail_count}` | å‰©ä½™ `{total_tasks - i}`")
                status_box.update(label=f"æ­£åœ¨å¤„ç† ({i+1}/{total_tasks}): {file.name}")
                current_log.info(f"ğŸ“„ æ­£åœ¨è¯»å–: `{file.name}`")
                
                try:
                    file.seek(0)
                    f_bytes = file.read()
                    m_type = file.type
                    
                    if m_type == "application/pdf":
                        current_log.markdown("&nbsp;&nbsp;ğŸ“„ PDF è½¬å›¾ç‰‡ä¸­...")
                        images = convert_from_bytes(f_bytes)
                        if images:
                            buf = io.BytesIO()
                            images[0].save(buf, format="JPEG")
                            f_bytes, m_type = buf.getvalue(), "image/jpeg"
                    elif m_type == 'image/jpg': m_type = 'image/jpeg'

                    # è°ƒç”¨è¯†åˆ«
                    result = analyze_invoice(f_bytes, m_type, current_log)
                    
                    if result:
                        st.session_state.invoice_cache[fid] = {'status': 'success', 'data': result}
                        current_log.success(f"âœ… `{file.name}` è¯†åˆ«æˆåŠŸï¼")
                        success_count += 1
                    else:
                        st.session_state.invoice_cache[fid] = {'status': 'failed'}
                        current_log.error(f"âŒ `{file.name}` è¯†åˆ«å¤±è´¥ (å·²è·³è¿‡)")
                        fail_count += 1
                
                except Exception as e:
                    st.session_state.invoice_cache[fid] = {'status': 'failed'}
                    current_log.error(f"âŒ å¼‚å¸¸é”™è¯¯: {e}")
                    fail_count += 1

                progress_bar.progress((i + 1) / total_tasks)
                time.sleep(1.0) # å¼ºåˆ¶å†·å´ï¼Œé˜²æ­¢æœ€åä¸€å¼ è¢«é™æµ

            # å¾ªç¯ç»“æŸ
            final_msg = f"âœ… å¤„ç†ç»“æŸï¼æˆåŠŸ {success_count} å¼ ï¼Œå¤±è´¥ {fail_count} å¼ ã€‚"
            if fail_count > 0:
                final_msg += " (å¤±è´¥æ–‡ä»¶å·²æ ‡è®°åœ¨è¡¨æ ¼ä¸­)"
            status_box.update(label=final_msg, state="complete", expanded=False)
            time.sleep(1.5)
            st.rerun()

    # --- 3. ç»“æœå±•ç¤º ---
    table_data = []
    failed_files = [] # æ”¶é›†å¤±è´¥æ–‡ä»¶ä¾›é‡è¯•
    
    for file in uploaded_files:
        fid = f"{file.name}_{file.size}"
        if fid in st.session_state.ignored_files: continue
        
        cache = st.session_state.invoice_cache.get(fid)
        
        if cache and cache['status'] == 'success':
            res = cache['data']
            try: amt = float(str(res.get('Total', 0)).replace(',','').replace('å…ƒ',''))
            except: amt = 0.0
            table_data.append({
                "æ–‡ä»¶å": file.name, "æ—¥æœŸ": res.get('Date', ''), "é¡¹ç›®": res.get('Item', ''), 
                "é‡‘é¢": amt, "çŠ¶æ€": "âœ… æˆåŠŸ", "file_id": fid
            })
        elif cache and cache['status'] == 'failed':
            failed_files.append(fid)
            table_data.append({
                "æ–‡ä»¶å": file.name, "æ—¥æœŸ": "-", "é¡¹ç›®": "-", 
                "é‡‘é¢": 0.0, "çŠ¶æ€": "âŒ å¤±è´¥", "file_id": fid
            })

    if table_data:
        df = pd.DataFrame(table_data)
        
        # å¤±è´¥é‡è¯•åŒº
        if failed_files:
            c1, c2 = st.columns([8, 2])
            with c1: st.warning(f"âš ï¸ æœ‰ {len(failed_files)} å¼ å‘ç¥¨è¯†åˆ«å¤±è´¥ã€‚æ‚¨å¯ä»¥æ£€æŸ¥ç½‘ç»œåï¼Œç‚¹å‡»å³ä¾§æŒ‰é’®å•ç‹¬é‡è¯•è¿™äº›æ–‡ä»¶ã€‚")
            with c2: 
                if st.button("ğŸ”„ é‡è¯•å¤±è´¥ä»»åŠ¡", type="primary", use_container_width=True):
                    # æ ¸å¿ƒé€»è¾‘ï¼šä»â€œå·²å¤„ç†é›†åˆâ€ä¸­ç§»é™¤è¿™äº›IDï¼Œä¸‹æ¬¡å¾ªç¯å°±ä¼šé‡æ–°å¤„ç†å®ƒä»¬
                    for fid in failed_files:
                        if fid in st.session_state.processed_session_ids:
                            st.session_state.processed_session_ids.remove(fid)
                    st.rerun()

        # è¡¨æ ¼
        edited_df = st.data_editor(
            df,
            column_config={
                "file_id": None, "é‡‘é¢": st.column_config.NumberColumn(format="%.2f"),
                "çŠ¶æ€": st.column_config.TextColumn(width="small", disabled=True),
                "æ–‡ä»¶å": st.column_config.TextColumn(disabled=True)
            },
            num_rows="dynamic", use_container_width=True, key="invoice_editor"
        )
        
        # åŒæ­¥é€»è¾‘
        current_ids = set(edited_df["file_id"])
        original_ids = set(df["file_id"])
        if len(current_ids) != len(original_ids):
            st.session_state.ignored_files.update(original_ids - current_ids)
            st.rerun()
            
        for index, row in edited_df.iterrows():
            fid = row['file_id']
            if fid in st.session_state.invoice_cache and st.session_state.invoice_cache[fid]['status'] == 'success':
                 st.session_state.invoice_cache[fid]['data']['Total'] = row['é‡‘é¢']

        # åº•éƒ¨æ 
        total = edited_df[edited_df['çŠ¶æ€'] == "âœ… æˆåŠŸ"]['é‡‘é¢'].sum()
        c_s1, c_main, c_s2 = st.columns([2.5, 5, 2.5])
        with c_main:
            i_l, i_r = st.columns([1.5, 1])
            with i_l:
                st.markdown(f"""<div class="total-container"><span class="total-label">ğŸ’° æ€»é‡‘é¢åˆè®¡</span><span class="total-value">Â¥ {total:,.2f}</span></div>""", unsafe_allow_html=True)
            with i_r:
                out = io.BytesIO()
                exp = edited_df.drop(columns=["file_id"])
                exp.loc[len(exp)] = ['åˆè®¡', '', '', total, '']
                with pd.ExcelWriter(out, engine='openpyxl') as writer: exp.to_excel(writer, index=False)
                st.download_button("å¯¼å‡º excel", out.getvalue(), "å‘ç¥¨æ±‡æ€».xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
