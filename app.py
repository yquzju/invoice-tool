import streamlit as st
import pandas as pd
import requests
import base64
import json
import io
from pdf2image import convert_from_bytes
import time

# --- âš ï¸ è¯·å¡«å…¥ä½ çš„ API Key ---
API_KEY = "AIzaSyARtowfN-m9H80rbXgpXGBR-xZQIzp8LSg"

def get_best_model():
    """
    è¯Šæ–­æ¨¡å¼ï¼šåˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹ï¼Œå¹¶è‡ªåŠ¨é€‰æ‹©ä¸€ä¸ª
    """
    try:
        url = f"https://generativelanguage.googleapis.com/v1beta/models?key={API_KEY}"
        response = requests.get(url)
        
        if response.status_code != 200:
            st.error(f"è¿æ¥ Google å¤±è´¥ (Status {response.status_code})ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ– API Keyã€‚")
            return None, []

        data = response.json()
        models = data.get('models', [])
        
        # ç­›é€‰æ”¯æŒç”Ÿæˆçš„æ¨¡å‹
        candidates = []
        for m in models:
            if 'generateContent' in m.get('supportedGenerationMethods', []):
                # åªä¿ç•™åå­—
                name = m['name'].replace('models/', '')
                candidates.append(name)
        
        if not candidates:
            return None, []
            
        # æ™ºèƒ½é€‰æ‹©ç­–ç•¥ï¼šä¼˜å…ˆæ‰¾ flash
        selected = candidates[0]
        for name in candidates:
            if 'flash' in name:
                selected = name
                break
                
        return selected, candidates

    except Exception as e:
        st.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        return None, []

def analyze_with_retry(image_bytes, mime_type, model_name):
    """
    é’ˆå¯¹ 2.5 æ¨¡å‹çš„æ…¢é€Ÿé‡è¯•é€»è¾‘
    """
    base64_image = base64.b64encode(image_bytes).decode('utf-8')
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={API_KEY}"
    headers = {'Content-Type': 'application/json'}
    
    payload = {
        "contents": [{
            "parts": [
                {"text": "Extract 3 fields into JSON:\n1. Item (Main product name, keep Chinese)\n2. Date (YYYY-MM-DD)\n3. Total (Number only)\n\nFormat: {\"Item\": \"...\", \"Date\": \"...\", \"Total\": 0.0}"},
                {
                    "inline_data": {
                        "mime_type": mime_type,
                        "data": base64_image
                    }
                }
            ]
        }]
    }
    
    # é’ˆå¯¹æ–°æ¨¡å‹çš„æ¿€è¿›é‡è¯•ç­–ç•¥
    for attempt in range(1, 4):
        try:
            response = requests.post(url, headers=headers, json=payload)
            
            if response.status_code == 200:
                # æˆåŠŸï¼
                try:
                    res_json = response.json()
                    text = res_json['candidates'][0]['content']['parts'][0]['text']
                    clean_text = text.replace("```json", "").replace("```", "").strip()
                    return json.loads(clean_text)
                except:
                    return None
            
            elif response.status_code == 429:
                # é‡åˆ°é™é€Ÿï¼Œæ ¹æ®æ¬¡æ•°æŒ‡æ•°çº§ç­‰å¾…
                wait_time = 15 * attempt  # ç¬¬ä¸€æ¬¡ç­‰15ç§’ï¼Œç¬¬äºŒæ¬¡ç­‰30ç§’...
                st.toast(f"â³ è§¦å‘é™é€Ÿ (429)ï¼Œæ­£åœ¨å†·å´ {wait_time} ç§’...", icon="ğŸ§Š")
                time.sleep(wait_time)
                continue
            
            else:
                st.warning(f"è¯·æ±‚æŠ¥é”™ {response.status_code}ï¼Œé‡è¯•ä¸­...")
                time.sleep(5)
                continue
                
        except Exception as e:
            st.error(f"ç½‘ç»œé”™è¯¯: {e}")
            time.sleep(5)
            
    return None

# --- é¡µé¢é€»è¾‘ ---
st.set_page_config(page_title="AI å‘ç¥¨åŠ©æ‰‹ (è¯Šæ–­ç‰ˆ)", layout="wide")
st.title("ğŸ§¾ AI å‘ç¥¨åŠ©æ‰‹ (è‡ªåŠ¨é™é€Ÿç‰ˆ)")

# 1. å¯åŠ¨æ—¶è‡ªåŠ¨è·å–æ¨¡å‹
if 'target_model' not in st.session_state:
    with st.spinner("æ­£åœ¨è¿æ¥ Google æœåŠ¡å™¨æ£€æµ‹å¯ç”¨æ¨¡å‹..."):
        best_model, all_models = get_best_model()
        if best_model:
            st.session_state['target_model'] = best_model
            st.session_state['all_models'] = all_models
        else:
            st.error("âŒ æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨æ¨¡å‹ï¼Œè¯·æ£€æŸ¥ Key æ˜¯å¦æœ‰æ•ˆã€‚")
            st.stop()

# æ˜¾ç¤ºå½“å‰çŠ¶æ€
st.info(f"ğŸš€ å·²è‡ªåŠ¨é”å®šå¯ç”¨æ¨¡å‹: **{st.session_state['target_model']}**")
with st.expander("æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ¨¡å‹åˆ—è¡¨ (è°ƒè¯•ç”¨)"):
    st.write(st.session_state.get('all_models', []))

# 2. æ–‡ä»¶ä¸Šä¼ 
uploaded_files = st.file_uploader("è¯·ä¸Šä¼ å‘ç¥¨", type=['png', 'jpg', 'jpeg', 'pdf'], accept_multiple_files=True)

if uploaded_files:
    st.divider()
    st.warning("âš ï¸ æ³¨æ„ï¼šæ£€æµ‹åˆ°ä½¿ç”¨çš„æ˜¯æœ€æ–°ç‰ˆæ¨¡å‹ï¼Œä¸ºé˜²æ­¢å°å·ï¼Œæ¯å¼ å›¾ç‰‡å¤„ç†é—´éš”è¾ƒé•¿ (10ç§’+)ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚")
    
    data_list = []
    progress_bar = st.progress(0)
    
    for index, file in enumerate(uploaded_files):
        # ğŸŸ¢ æ ¸å¿ƒé™é€Ÿé€»è¾‘ï¼šæ¯å¤„ç†ä¸€å¼ å‰ï¼Œå¼ºåˆ¶ä¼‘æ¯ 10 ç§’
        if index > 0:
            with st.spinner(f"â³ æ­£åœ¨å†·å´ï¼Œé˜²æ­¢é™é€Ÿ (10ç§’)..."):
                time.sleep(10)
        
        try:
            # é¢„å¤„ç†
            file_bytes = file.read()
            process_bytes = file_bytes
            mime_type = file.type
            
            if file.type == "application/pdf":
                images = convert_from_bytes(file_bytes)
                if images:
                    img_buffer = io.BytesIO()
                    images[0].save(img_buffer, format="JPEG")
                    process_bytes = img_buffer.getvalue()
                    mime_type = "image/jpeg"
            if mime_type == 'image/jpg': mime_type = 'image/jpeg'

            # è¯†åˆ«
            st.toast(f"æ­£åœ¨å¤„ç†: {file.name}")
            result = analyze_with_retry(process_bytes, mime_type, st.session_state['target_model'])
            
            if result:
                try:
                    amt = float(str(result.get('Total', 0)).replace('Â¥','').replace(',',''))
                except:
                    amt = 0.0
                
                data_list.append({
                    "æ–‡ä»¶å": file.name,
                    "å¼€ç¥¨æ—¥æœŸ": result.get('Date', ''),
                    "å‘ç¥¨é¡¹ç›®": result.get('Item', ''),
                    "ä»·ç¨åˆè®¡": amt
                })
                st.success(f"âœ… {file.name} å¤„ç†å®Œæˆ")
            else:
                 st.error(f"âŒ {file.name} å¤±è´¥")

        except Exception as e:
            st.error(f"å¼‚å¸¸: {e}")
            
        progress_bar.progress((index + 1) / len(uploaded_files))

    # 3. ç»“æœå¯¼å‡º
    if data_list:
        df = pd.DataFrame(data_list)
        total = df['ä»·ç¨åˆè®¡'].sum()
        
        st.dataframe(df, use_container_width=True)
        st.metric("ğŸ’° æ€»è®¡", f"Â¥ {total:,.2f}")
        
        df_export = df.copy()
        df_export.loc[len(df_export)] = ['åˆè®¡', '', '', total]
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df_export.to_excel(writer, index=False)
            
        st.download_button("ğŸ“¥ ä¸‹è½½ Excel è¡¨æ ¼", output.getvalue(), "å‘ç¥¨æ±‡æ€».xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", type="primary")
